"""
Module: Subroutine Driver and Differentiable Stack Framework

This module is responsible for connecting a user-defined model (via a SubroutineCore) to a differentiable
stack that can manage dynamic subroutine calls in a neural network. The key elements of this framework
are the SubroutineCore interface, which acts as a bridge between the model and the stack, and the
SubroutineDriver, which manages subroutine execution based on action probabilities.

### Key Features:
1. **SubroutineCore Interface**:
    - A user-implemented interface that defines the core computational engine.
    - The `setup_state` method returns a set of subroutine stubs (a pytree structure) that the driver uses.
    - The `forward` method takes in subroutine states and other parameters and produces action logits and updated states.
    - This allows the model to participate in the stack's dynamics, where actions like creating, maintaining,
      or returning from subroutines are explored.

2. **SubroutineDriver**:
    - Manages the full lifecycle of subroutine execution using the core model and differentiable stack.
    - Upon initialization, the driver receives configuration parameters such as stack depth, iteration limits,
      and probabilistic pointers.
    - When the driver is called, it enters subroutine mode and runs through iterations where the core model
      processes the current stack state.
    - The final output of the driver is the accumulated results from the stack, which have been merged via the
      probabilistic mechanism.

3. **Pytree of Subroutine Stubs**:
    - The model is expected to return and manage a pytree of subroutine stubs. These represent the stateful
      parts of the stack that will be used and modified during execution.
    - The stubs are passed in through `setup_state` and used by the subroutine driver to manage stack operations.

### Implementation Details (For Developers):

1. **Probabilistic Pointers**:
   - Each stack level is weighted by probabilistic pointers. These pointers represent the "focus" or
     "long_term_memories" at each depth, meaning that stack element 1 might be active with 30% probability
      and element 2 with 70%. This allows for smooth transitions between subroutines during
      differentiable training.

2. **Superposition for I/O**:
   - When the model reads from the stack, it gets a superposition of the active stack
     elements weighted by the probabilistic pointers. When writing back to the stack,
     a similar superposition is applied, allowing multiple states to influence the outcome
     in a differentiable manner.

3. **Action Decisions (Return, Maintain, Create)**:
   - Every iteration, the model must decide whether to return from subroutines, maintain the
     current subroutine, or create a new one. These decisions are driven by **action logits**
     generated by the core model.
   - All three actions (return, maintain, create) are explored, with their results combined
     using superposition to update the new stack state.

4. **Handling Lost Probability and Accumulation**:
   - If a return action causes state information to "fall off" the top of the stack, this lost probability
     is accumulated in a special **accumulator**. The accumulation process resembles an ACT-like
     (Adaptive Computation Time) mechanism, where the lost probability and its associated tensor
     are combined over time.
   - Once all probability has been accumulated (i.e., the stack has no remaining active probability),
     the subroutine halts, and the accumulated result is returned.
"""


import torch
from torch import nn
from torch.nn import functional as F
from typing import List, Dict, Tuple, Union, Optional
from abc import abstractmethod
from .subroutine_stubs import SubroutineLogicStub

from src.main.model.base import TensorTree, parallel_pytree_map

# Define important external types
SubroutineStubTree = Union[SubroutineLogicStub,
                           List['SubroutineStubTree'],
                           Tuple['SubroutineStubTree', ...],
                           Dict[str, 'SubroutineStubTree']
                           ]

# Define important internal types.
#
# NOTE: We are jumping through some extra hoops to keep all type declarations in
# one place. The function will be checked on the second compiler pass, which means
# we can declare the type before we actually defined it in terms of line number.

def make_stack_tree_type():
    StackTree = Union['SubroutineStackTracker',
                     List['StackTree'],
                     Tuple['StackTree', ...],
                     Dict[str, 'StackTree']]
    return StackTree

def make_accumulator_tree_type():
    AccumulatorTree = Union['SubroutineAccumulator',
                            List['AccumulatorTree'],
                            Tuple['AccumulatorTree', ...],
                            Dict[str, 'AccumulatorTree']]
    return AccumulatorTree


StackTree = make_stack_tree_type()
AccumulatorTree = make_accumulator_tree_type()




# Define a very important utility function. This allows the user to specify
# their state tensorflow style however they wish.

# Define user features.
class SubroutineCore(nn.Module):
    """
    The interface for the computational engine that can be
    put inside a subroutine driver. It provides the parameters
    to use the state of the stack to perform computations. It also
    will produce embeddings and state output that can be used
    to manage the subroutine stack

    A very simple example, of a LSTM

    """
    @abstractmethod
    def setup_state(self,
                    batch_shape: torch.Size,
                    initial_states: TensorTree,
                    *parameters
                    )->SubroutineStubTree:
        """
        Sets up state based on the provided tensor of embeddings.

        :param batch_shape: shape of batch dims,
        :param initial_states: The collection of state we can use to set things up
        :return: Whatever state we need. In the form of a pytree. Stubs will be initialized.
        """
    @abstractmethod
    def forward(self,
                states: TensorTree,
                **parameters)->Tuple[torch.Tensor, TensorTree]:
        """
        Performs the forward pass. Tensor is a tensor of embeddings, while states is any
        state information that needs to be tracked.
        :param states: Whatever states you need to operate. This pytree
                       will corrolate directly with the subroutine stub tree
        :param parameters: Any extra parameters that are passed. I dunno, temperature?
        :return: The actions probabilities, and the state tensortree
            - Action logits.
                - Shape (...batch_shape, 3)
                - Used to determine actions. Use linear projection
            - States:
                - Any revised states
                - This will be incorporated back into the broader subroutine context.
                - A pytree of tensors. However, tensors must have consistent shapes across invokations.
        """
        pass



class ActionsProbabilities:
    """
    Manages the creation of action probabilities from
    logits. Also tracks certain statistics and state
    information. Note that index 0: return, index 1: maintain,
    index 2: create.
    """

    @property
    def can_pop(self)->bool:
        return self.num_iterations >= self.num_iterations_before_pop

    def __init__(self,
                 num_iterations_before_can_pop: int,
                 num_iterations_before_forced_flush: int,
                 gumbel_softmax: bool
                 ):
        """
        :param num_iterations_before_can_pop: Number of context expressions before returning off stack is option
        :param num_iterations_before_forced_flush: Number of context expressions before you MUSt return off stack
        :param gumbel_softmax: Whether or not to use gumbel softmax when forming the action probabilities. If
                               used, we will perform a hard sample.
        """
        self.num_iterations = 0
        self.num_iterations_before_pop = num_iterations_before_can_pop
        self.num_before_flush = num_iterations_before_forced_flush
        self.gumbel_softmax = gumbel_softmax
    def __call__(self,
                 action_logits: torch.Tensor,
                 gumbel_temperature: float = 1.0
                 )->torch.Tensor:
        """
        :param action_logits: The action logits, used to make the action probabilities.
            - Shape (..., 3)
        :param gumbel_temperature: The gumbel temperature. Only relevant if using
                                   gumbel softmax when selecting action probabilies
        :return: The action probabilities
            - Shape (..., 3)
        """
        logit = action_logits.clone()
        if self.num_iterations >= self.num_before_flush:
            # We are in the forced flush state. Mask out the create subroutine
            # and maintain subroutine option. We can then only return from
            # subroutine
            logit[..., 1] = -1e9
            logit[..., 2] = -1e9
        if self.gumbel_softmax:
            action_probabilities = F.gumbel_softmax(logit, gumbel_temperature, dim=-1)
        else:
            action_probabilities = F.softmax(logit, dim=-1)

        self.num_iterations += 1
        return action_probabilities


class ProbabilisticPointers:
    """
    The probabilistic pointer management class. Tracks and modifies
    the probabilistic pointers.

    Probabilistic pointers distribute the focus across stack levels, allowing
    actions like `enstack`, `no-op`, and `destack` to adjust how long_term_memories is
    split across the levels of the stack.

    It handles rolling of the pointers based on the action probabilities and
    ensures that any probability that rolls off the end (or beginning) of the
    stack is masked out and discarded instead of wrapping around.
    """
    @property
    def is_active(self) -> bool:
        """
        Returns false when the stacks have all become inactive
        :return: bool.
        """
        return torch.any(self.is_batch_active)

    @property
    def is_batch_active(self)->torch.Tensor:
        """
        Checks, for all batch dims, whether the indicated elements of the
        stack are still active.
        :return: A tensor indicating boolean truth values
        """
        return self.stack_probability <= self.activity_epsilon

    @property
    def stack_probability(self)->torch.Tensor:
        """
        Indicates the remaining probability in the stack.
        :return: A tensor of shape (...). Probability
        """
        return self.pointers.sum(dim=0)


    def __init__(self,
                 probabilistic_pointers: torch.Tensor,
                 activity_epsilon: float = 1e-4
                 ):
        """
        Initializes the probabilistic pointer class.

        :param probabilistic_pointers: The probabilistic pointers matching the
                                       situation. It has been assumed they were loaded already.
                                       Shape (stack_size, ...)
        :param activity_epsilon: The epsilon value to use when deciding if a stack is active
               or not.
        """
        self.pointers = probabilistic_pointers
        self.activity_epsilon = activity_epsilon

    def get(self)->torch.Tensor:
        """
        Gets the current probabilistic pointers
        :return: The probabilistic pointers
        """
        return self.pointers
    def create_scenario_pointers(self,
                                can_pop: bool
                                )->Tuple[torch.Tensor, torch.Tensor]:
        """
        Creates the probabilistic scenario pointers. These are pointers
        that are, hypothetically, pointing at the location we will
        end up at if we were to do a "return", "maintain", or "create"
        subroutine action.

        This will, in essence, end up telling us where we need to write.

        :param can_pop: A bool. If this is false, we are not allowed to pop off
                        the end of the stack, and instead probability would accumulate
        :return:
            - The scenario pointers, covering the three scenarios.
                - Shape (stack_size, ..., 3)
            - The lost probability
                - Only nonzero if can pop is true
                - Shape (...)
                - Indicates what probability was lost off the top of the stack
        """

        # In order to accomplish the creation of the scenario pointers,
        # basically the return action is made to point one higher in the stack
        # the maintenance pointer does not change, and the create pointers go
        # one deeper. Then there is some masking and accumulation behavior.

        pointers = []

        # Create the return pointers. We roll earlier into the stack,
        # then must handle any probability accumulation or compensation

        return_pointers = self.pointers
        return_pointers = return_pointers.roll(-1, dims=0)

        if can_pop:
            # The lost probability is what rolled off the beginning of the stack,
            # to the end. Fetch it, then mask that out.
            lost_probability = return_pointers[-1].clone()
            return_pointers[-1] = 0
        else:
            # The lost probability is none, as we cannot lose probability yet.
            # We instead accumulate whatever rolled off the end in slot zero,
            # basically moving the probability if it rolled off the end of the stack.
            lost_probability = torch.zeros_like(return_pointers[-1])
            return_pointers[0] += return_pointers[-1]
            return_pointers[-1] = 0
        pointers.append(return_pointers)

        # Handle the maintain subroutine operation. It, perhaps unsuprisingly, means
        # no change is made in pointer positioning.

        pointers.append(self.pointers)

        # Handle the create suproutine operation. In this case, we roll one deeper
        # into the stack. Also, since we cannot roll probability off the end of the stack,
        # we instead accumulate probability near the end and mask out the beginning.

        # Roll to go one deeper into the stack
        create_pointers = self.pointers.roll(1, dims=0)

        # Now, some probability rolled off the end of the stack and
        # ended up at the beginning. Move it back to the end, and mask
        # the beginning

        create_pointers[-1] += create_pointers[0]
        create_pointers[0] = 0

        # Append
        pointers.append(create_pointers)

        # Now, create the final return, and return

        return torch.stack(pointers, dim=-1), lost_probability

    def update_superposition(self,
                             action_probabilities: torch.Tensor,
                             scenario_pointers: torch.Tensor
                             ):
        """
        Updates the internal pointer superposition based on the
        scenario pointers, and the action probabilities. Basically,
        we end up doing a weighted sum across the probability distributions.

        Which still ends up with probability distributions.
        :param action_probabilities: The action probabilities. Shape (..., 3)
        :param scenario_pointers: The scenario pointers. Shape (stack_size, ..., 3)
        """
        self.pointers = torch.sum(scenario_pointers * action_probabilities.unsqueeze(0), dim=-1)




class SubroutineStackTracker:
    """
    Manages the subroutine stack and associated ideas.
    Also responsible for proposing new stack state options
    under the return from subroutine, maintain subroutine,
    and create subroutine computation branches.
    """
    def __init__(self,
                 stack: torch.Tensor,
                 logic: SubroutineLogicStub,
                 ):
        self.stack = stack
        self.logic = logic
    def get(self, pointer_probabilities: torch.Tensor)->torch.Tensor:
        """
        Gets the subroutine context, based on the provided pointer probabilities.
        :param pointer_probabilities: The pointer probabilities. Shape (stack_depth, ...batch)
        :return: The expressed context.. Shape (...batch, ...custom)
        """

        # The pointer probabilities may not be expressed over the entire stack.
        # Unsqueeze it a bit if needed
        while pointer_probabilities.dim() < self.stack.dim():
            pointer_probabilities = pointer_probabilities.unsqueeze(-1)

        # Run weighting action, then add.
        return torch.sum(pointer_probabilities*self.stack, dim=0)
    def compute_scenario_outcomes(self)->torch.Tensor:
        """
        Computes the three parallel stack state outcomes for all
        depths in the stack. This basically returns every possible
        outcome. We will use probabilities to actually figure out
        how much each update matters.

        :return: The scenario outcomes.
            - Shape (stack_size, ..., 3)
            - for 3: "return", "maintain", or "create"
            - What we look like after each activity
        """
        outcomes: List[torch.Tensor] = []
        outcomes.append(self.logic.return_from_subroutine(self.stack))
        outcomes.append(self.logic.create_subroutine(self.stack))
        outcomes.append(self.logic.maintain_subroutine(self.stack))
        return torch.stack(outcomes, dim=-1)
    def integrate_update(self,
                         action_probabilities: torch.Tensor,
                         scenario_pointers: torch.Tensor,
                         update: torch.Tensor
                         ):
        """
        Integrates a given set of scenario and action information to
        produced the revised stack. Does this by running all possibilities
        in parallel then updating according to pointer weights.

        :param action_probabilities: The action probabilities
            - Indicates how strongly we thing the return, maintain, create action occurs,
              respectively, along 3
            - Shape (..., 3)
        :param scenario_pointers: The pointers we write to under the three scenarios
            - Shape (stack_size, ..., 3)
            - Again, return, maintain, create.
        :param update: A tensor we need to integrate into the stack at the proper position.
            - Shape (...)
        """

        # Begin by computing the outcomes for performing each scenario at
        # each stack level.

        scenario_options = self.compute_scenario_outcomes() #(stack_depth, ..., 3)

        # These options now have the update integrated into them

        scenario_options = self.logic.update_subroutine(update, scenario_options)

        # The actual stacks during each computation branch are an interpolation
        # between these outcomes, and how much we can actually write into
        # each position.

        scenario_stacks = self.stack*(1-scenario_pointers) + scenario_options*scenario_pointers

        # And finally, we merge these branches using the action probabilities

        self.stack = torch.sum(scenario_stacks*action_probabilities.unsqueeze(0), dim=-1)


class SubroutineAccumulator:
    """
    Contains a safe space for subroutines to accumulate their
    results in. The subroutine mechnanism accumulates output
    from the top of the stack using a superposition based on
    probabilities, much like Adaptive Computation Time. This
    is the place those are stored while running

    An implementation detail to note is that not all states
    may actually end up accumulated. Indeed, in such cases
    this will return a None on get, and be initialized
    with None as well, and will not produce a performance penalty
    """
    @property
    def is_accumulation_needed(self)->bool:
        return self.accumulator is not None
    def get(self) -> torch.Tensor:
        """ Gets the contents of the accumulator"""
        return self.accumulator

    def __init__(self,
                 accumulator: Optional[torch.Tensor]
                 ):
        self.accumulator = accumulator

    def accumulate(self,
                     lost_probability: torch.Tensor,
                     tensor: torch.Tensor
                     ):
        """
        Stores the values in the accumulator.
        :param lost_probability: The lost probability to accumulate with.
            - Shape (...)
        :param tensor: The tensor to store away.
            - Shape (..., ...)
        """
        if self.accumulator is None:
            raise ValueError("Attempt to accumulate on something that does not support it.")
        while lost_probability.dim() < tensor.dim():
            lost_probability = lost_probability.unsqueeze(-1)
        self.accumulator += lost_probability * tensor


# Define the subroutine statistics tracker class

class SubroutineStatistics:
    """
    Class for gathering subroutine statistics.
    """
    def __init__(self,

                 ):
        pass



# Define important internal types
class DifferentiableSubroutine:
    """
    A differentiable stack for handling subroutine creation, execution, and
    return, along with integration of subroutine updates into the subroutine
    stacks.

    Multiple stacks can be managed in parallel with their own unique create,
    maintain, return, and update logic. However, they all are synchronized
    in terms of a single set of probabilistic pointers that let us display only a single
    context when running the rest of the model.

    Updates must be provided in the same manner as the stack trackers were provided.
    """

    def __init__(self,
                 actions_manager: ActionsProbabilities,
                 probabilistic_pointers: ProbabilisticPointers,
                 subroutines: StackTree,
                 accumulators: AccumulatorTree
                 ):
        """
        :param actions_manager: Creates action probabilities, and tracks iterations
        :param probabilistic_pointers: The probabilistic pointers
        :param subroutines: A Pytree stack containing the setup subroutine stacks.
        """
        self.actions_manager = actions_manager
        self.probabilistic_pointers = probabilistic_pointers
        self.subroutines = subroutines
        self.accumulators = accumulators

    def get_context_expression(self)->TensorTree:
        """
        Gets an expression of the subroutine context. This can be used
        by the model
        :return: The subroutine tensortree.
        """
        pointer_probabilities = self.probabilistic_pointers.get()
        def get_expressed_state(stack_tracker: SubroutineStackTracker)->torch.Tensor:
            return stack_tracker.get(pointer_probabilities)
        return parallel_pytree_map(get_expressed_state, self.subroutines)

    def get_accumulators(self)->TensorTree:
        """
        Gets the accumulated results. Inactive accumulators are not
        expressed.
        :return:
        """

        def get_accumulator_content(accumulator: SubroutineAccumulator)->Optional[torch.Tensor]:
            """
            Gets the subroutine accumulator value. Some accumulators may return none. These are
            not expressed in the pytree.
            :param accumulator: The accumulator to fetch from
            :return: The accumulator value. Or none, if the accumulator is inactive.
            """
            return accumulator.get()

        return parallel_pytree_map(get_accumulator_content, self.accumulators)


    def update(self,
               action_logits: torch.Tensor,
               updates: TensorTree,
               gumbel_temperature: float,
               )->TensorTree:
        """
        Performs an update against the differentiable subroutine.
        Each individual expressed subroutine state is expected to have subroutine
        updates that will be created and expressed in the update tree, in the same
        way as was seen during the get action. These will be integrated according
        to the subroutine logic.

        :param action_logits: The action logits.
        :param updates: The updates for each subroutine state piece, in the
                        stackless space.
        :param gumbel_temperature: Only relevant when interpreting the action logits
                                   using gumbel softmax.
        :return: The lost subroutine state. Found by multiplying the updates by the
                 lost probability - these will never end up somewhere inside the stack.
        """

        # Perform the probabilistic computation actions.
        action_probabilities = self.actions_manager(action_logits, gumbel_temperature)
        scenario_pointers, lost_probability = self.probabilistic_pointers.create_scenario_pointers(
                                                                    self.actions_manager.can_pop)
        self.probabilistic_pointers.update_superposition(action_probabilities, scenario_pointers)

        #Define and perform the actual state update.
        def perform_update(update: torch.Tensor,
                           stack_tracker: SubroutineStackTracker,
                           accumulator: SubroutineAccumulator
                           ):
            """
            Updates the subroutine stack trackers. Creates the lost state output trees
            :param update: The update to incorporate
            :param stack_tracker: The state tracker to incorporate it on
            :param accumulator: The accumulator to use.
            """

            # Perform the actual update action. Integration is performed
            # using the action probabilities and the scenario pointers
            stack_tracker.integrate_update(action_probabilities,
                                           scenario_pointers,
                                           update)

            # Accumulate, if needed

            if accumulator.is_accumulation_needed:
                accumulator.accumulate(lost_probability, update)

        # Run the update. Entirely stateful using side effects.
        parallel_pytree_map(perform_update, updates, self.subroutines, self.accumulators)




class SubroutineStubFactory(nn.Module):
    """
    The subroutine logic stubs contain most of what
    is needed to setup each subroutine. However, they
    would not have been initialized to the proper stack depth.

    This finishes that setup. When called with a subroutine
    stub tree, it will use the information in the stub
    to setup the a SubroutineStackTracker to the appropriate
    depth, in the same position on the user pytree.
    """
    def __init__(self,
                 stack_depth: int,
                 use_gumbel_softmax: bool,
                 activity_epsilon: float = 1e-4
                 ):
        """

        :param stack_depth: How deep the stack goes
        :param activity_epsilon:
                    When probability in stack dips below this point, the stack is considered halted.
        """
        self.stack_depth = stack_depth
        self.use_gumbel_softmax = use_gumbel_softmax
        self.activity_epsilon = activity_epsilon


    def create_stack_trackers(self,
                              stub_trees: SubroutineStubTree
                              )->Tuple[StackTree, torch.dtype, torch.device]:
        """
        Creates the subroutine stack trackers. While we are at it, we
        also go and figure out the dtype and device to initialize on.
        :param stub_trees: The pytree containing the various logic stubs that need
        initialization
        :return:
            - The stack tree. Same shaped pytree, but we have stack trackers as leaves instead.
            - The dtype of the stubs
            - The device of the stubs
        """

        # Janky side effect storage since python does not have single element storage preset
        dtype_indirection = []
        device_indirection = []

        # Create the initialization function. This will be mapped across the
        # pytree leaves, and should return the SubroutineStackTracker for that
        # stub. It also stores and checks dtye and device info
        def setup_stack_tracker(logic_stub: SubroutineLogicStub)->SubroutineStackTracker:
            # Get starting state off logic stub
            seed_state = logic_stub.seed_state

            # Set aside dtype and device for pointer creation
            if len(dtype_indirection) ==0:
                dtype_indirection.append(seed_state.dtype)
                device_indirection.append(seed_state.device)
            else:
                assert seed_state.device == dtype_indirection[0]
                assert seed_state.dtype == device_indirection[0]

            # Create stack. Insert starting values

            stack = torch.zeros([self.stack_depth] + list(seed_state.shape),
                                dtype=seed_state.dtype, device=seed_state.device)
            stack[0] = seed_state

            # Create stack TRACKER

            tracker = SubroutineStackTracker(stack, logic_stub)

            # Return

            return tracker

        # Apply the map to the pytree. We now should have cached dtype, device
        # information, and the leaves are now state trackers.

        stack_tree = parallel_pytree_map(setup_stack_tracker, stub_trees)

        # Return

        return stack_tree, dtype_indirection.pop(), device_indirection.pop()

    def create_accumulators(self, stub_tree: SubroutineStubTree)->AccumulatorTree:
        """
        Creates the corresponding accumulator trees using the stub tree
        :param stub_tree: The stub tree to initialize with
        :return: The accumulator tree.
        """

        def setup_accumulator(logic_stub: SubroutineLogicStub)->SubroutineAccumulator:
            # Sets up the accumulator, based on the logic stub.
            # We basically either initialize it with zeros matching
            # the shape of the seed. Or none.

            if logic_stub.should_accumulate:
                accumulator_tensor = torch.zeros_like(logic_stub.seed_state)
                return SubroutineAccumulator(accumulator_tensor)
            else:
                return SubroutineAccumulator(None)

        accumulators = parallel_pytree_map(setup_accumulator, stub_tree)
        return accumulators


    def create_probabilistic_pointers(self,
                                      batch_shape: torch.Size,
                                      dtype: torch.dtype,
                                      device: torch.device
                                      )->ProbabilisticPointers:
        """
        Creates the probabilistic pointer object, once we know
        the batch shape, the dtype, and the device.

        :param batch_shape: Exactly what it says. The batch shape. Can be 1d or multidim.
        :param dtype: The dtype to make the pointers under
        :param device: The device to make the pointers under
        :return: The probabilistic pointers
        """

        # Create the pointers

        probabilistic_pointers = torch.zeros([self.stack_depth] + list(batch_shape),
                                             dtype=dtype, device=device)

        # The first element of the pointers should be locked, with 100% probability,
        # onto the first element of the stack. Place it there.

        probabilistic_pointers[0] = 1.0

        # Create and return the class

        return ProbabilisticPointers(probabilistic_pointers,
                                     self.activity_epsilon)

    def forward(self,
                batch_shape: torch.Size,
                stub_trees: SubroutineStubTree,
                num_iterations_before_pop_allowed: int,
                num_iterations_before_pop_required: int
                )->DifferentiableSubroutine:
        """
        Initialize all stub trees, replacing them in the same
        position with stack trackers. Then wrap it all in a
        differentiable subroutine.

        :param batch_shape: The shape of the batch elements. Used to initialize the pointers.
        :param stub_trees: The stub trees, indicating how to initialize
        :param num_iterations_before_pop_allowed: Indicates how many iterations in the stack must occur before
                                                    probability can start coming off the stack
        :param num_iterations_before_pop_required: Indicates how many iterations in the stack must occur
                                                   before the only action that can happen is pop.
        :return: The initialized differentiable subroutine
        """

        actions_manager = ActionsProbabilities(num_iterations_before_pop_allowed,
                                               num_iterations_before_pop_required,
                                               self.use_gumbel_softmax)

        subroutines_tree, dtype, device = self.create_stack_trackers(stub_trees)
        probabilistic_pointers = self.create_probabilistic_pointers(batch_shape,
                                                                    dtype,
                                                                    device)
        accumulators = self.create_accumulators(stub_trees)

        return DifferentiableSubroutine(actions_manager,
                                        probabilistic_pointers,
                                        subroutines_tree,
                                        accumulators)



class SubroutineDriver:
    """
    A core stack driver layer designed to allow the usage
    of the differentiable stack factory automatically with an
    internal core computation layer.
    """

    def __init__(self,
                 stack_depth: int,
                 core: SubroutineCore,
                 use_gumbel_softmax: bool,
                 activity_epsilon: float = 1e-4,
                 ):
        self.stub_factory = SubroutineStubFactory(stack_depth, use_gumbel_softmax, activity_epsilon,)
        self.core = core

    def forward(self,
                initial_states: TensorTree,
                batch_shape: torch.Size,
                max_iterations_before_flush: int,
                min_iterations_before_pop: int,
                gumbel_temperature: float,
                **parameters
                )->TensorTree:
        """
        Runs the actual driven subroutine process. Involves the setup, the
        running of the subroutine, and the return

        :param initial_states: The tensor, presumably of embeddings, that we need to process
        :param batch_shape: The batch shape portions of the tensor.
        :param max_iterations_before_flush: Think of it as a maximum computation limit
        :param min_iterations_before_pop: Think of it as a minimum computation limit.
        :param gumbel_temperature: Only used if gumbel softmax action sampling is in use. Ot
        :param parameters: Anything else you wish to pass in. Like temperature, perhaps?
        :return: At the moment
            - The accumulated output
            - PLANNED: Statistics.
        """

        stubs = self.core.setup_state(batch_shape, initial_states, *parameters)
        differentiable_subroutine: DifferentiableSubroutine = self.stub_factory(batch_shape, stubs,
                                                      min_iterations_before_pop,
                                                      max_iterations_before_flush
                                                      )
        while differentiable_subroutine.probabilistic_pointers.is_active:
            expressed_pytree = differentiable_subroutine.get_context_expression()
            action_logits, updated_state = self.core(expressed_pytree, **parameters)
            differentiable_subroutine.update(action_logits, updated_state, gumbel_temperature)

        return differentiable_subroutine.get_accumulators()





